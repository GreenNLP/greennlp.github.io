---
layout: doc
title:  "Benchmarking large-scale LLM training on LUMI"
date:   2024-01-11
categories: news
---
CSC, a partner in the GreenNLP project, has evaluated the scalability of large language model (LLM) training on the LUMI supercomputer. The results indicate that there are no fundamental scaling bottlenecks even when training with thousands of GPUs.

You can read more about the evaluation [on CSC's website](https://www.lumi-supercomputer.eu/scaling-the-pre-training-of-large-language-models-of-100b-parameters-to-thousands-of-amd-mi250x-gpus-on-lumi/).
